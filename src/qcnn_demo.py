import pennylane as qml
import torch
import numpy as np
import matplotlib.pyplot as plt
import time
import os

# ================= 1. é»„é‡‘é…ç½® (Best Configuration) =================
n_qubits = 16
dev = qml.device("lightning.qubit", wires=n_qubits)

# ç»è¿‡è°ƒè¯•çš„æœ€ä½³è¶…å‚æ•°
CONFIG = {
    "n_layers": 4,        # 4å±‚è¶³å¤Ÿæ•æ‰ç‰¹å¾ï¼Œåˆä¸ä¼šè¿‡æ‹Ÿåˆ
    "batch_size": 8,      # æ¯æ¬¡8ä¸ªæ ·æœ¬ï¼Œæ¢¯åº¦ä¼°è®¡è¾ƒå‡†
    "steps": 80,          # 80æ­¥ï¼Œç¡®ä¿ Loss å½»åº•æ”¶æ•›
    "lr": 0.04,           # å­¦ä¹ ç‡
    "save_path": "q_model_weights.pt" # ä¿å­˜è·¯å¾„
}

# ================= 2. ç­‰å˜ç”µè·¯ (The Core) =================
@qml.qnode(dev, interface="torch")
def equivariant_circuit(inputs, weights):
    # Encoding (4x4)
    for i in range(16): qml.RX(inputs[i], wires=i)
    
    # Variational Layers
    for l in range(weights.shape[0]):
        # [æ‹“æ‰‘å¯¹ç§°æ€§]
        # å†…åœˆæ—‹è½¬ (å…±äº«å‚æ•° 0)
        for i in [5, 6, 9, 10]: qml.RY(weights[l, 0], wires=i)
        # å¤–åœˆæ—‹è½¬ (å…±äº«å‚æ•° 1)
        for i in [0,1,2,3,7,11,15,14,13,12,8,4]: qml.RY(weights[l, 1], wires=i)
        
        # [å¯¹ç§°çº ç¼ ]
        # å†…åœˆç¯ (å…±äº«å‚æ•° 2)
        qml.CRZ(weights[l, 2], wires=[5, 6]); qml.CRZ(weights[l, 2], wires=[6, 10])
        qml.CRZ(weights[l, 2], wires=[10, 9]); qml.CRZ(weights[l, 2], wires=[9, 5])
        
        # å¤–åœˆç¯ (å…±äº«å‚æ•° 3)
        outer = [0,1,2,3,7,11,15,14,13,12,8,4]
        for k in range(len(outer)): 
            qml.CRZ(weights[l, 3], wires=[outer[k], outer[(k+1)%len(outer)]])
        
        # å†…å¤–è¿æ¥ (å…±äº«å‚æ•° 4)
        qml.CRZ(weights[l, 4], wires=[0, 5]); qml.CRZ(weights[l, 4], wires=[3, 6])
        qml.CRZ(weights[l, 4], wires=[12, 9]); qml.CRZ(weights[l, 4], wires=[15, 10])
    
    # [ä¸å˜æµ‹é‡] æ€»ç£çŸ©
    obs = qml.PauliZ(0)
    for i in range(1, 16): obs = obs + qml.PauliZ(i)
    return qml.expval(obs)

# ================= 3. ä¸»ç¨‹åº =================
def run_best_model():
    # --- A. æ•°æ®æ£€æŸ¥ ---
    if not os.path.exists('shared_digits_data.pt'):
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ 'shared_digits_data.pt'ã€‚")
        print("è¯·å…ˆè¿è¡Œ data_loader.py ç”Ÿæˆæ•°æ®ï¼")
        return

    print(f"ğŸ“¥ æ­£åœ¨åŠ è½½æ•°æ®...")
    data = torch.load('shared_digits_data.pt', weights_only=False)
    tx, ty = data['train_x'], data['train_y']
    
    # é¢„å¤„ç†å‡½æ•°
    def q_prep(imgs):
        # 8x8 -> 4x4 -> Normalize to [0, pi]
        imgs_4x4 = imgs.reshape(-1, 4, 2, 4, 2).mean(4).mean(2).reshape(-1, 16)
        return torch.tensor(imgs_4x4 / 16.0 * np.pi, dtype=torch.float32)

    # --- B. æ¨¡å‹åˆå§‹åŒ– ---
    weights = torch.randn(CONFIG["n_layers"], 5, requires_grad=True)
    opt = torch.optim.Adam([weights], lr=CONFIG["lr"])
    
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ (Target: >90% Accuracy)")
    print(f"é…ç½®: Layers={CONFIG['n_layers']} | Steps={CONFIG['steps']} | Batch={CONFIG['batch_size']}")
    
    start_time = time.time()
    loss_history = []

    # --- C. è®­ç»ƒå¾ªç¯ ---
    for step in range(CONFIG["steps"]):
        opt.zero_grad()
        
        # Mini-batch
        batch_idx = np.random.choice(len(tx), CONFIG["batch_size"])
        x_batch = tx[batch_idx]
        y_batch = ty[batch_idx]
        
        # ç›®æ ‡: 0 -> +1.0, 1 -> -1.0
        target = torch.tensor(np.where(y_batch == 0, 1.0, -1.0), dtype=torch.float32)
        
        # Forward
        x_ready = q_prep(x_batch)
        preds = torch.stack([equivariant_circuit(x, weights) for x in x_ready]) / 16.0
        
        loss = torch.mean((preds - target)**2)
        loss.backward()
        opt.step()
        
        loss_history.append(loss.item())
        
        if step % 10 == 0 or step == CONFIG["steps"]-1:
            elapsed = time.time() - start_time
            print(f"Step {step:02d}/{CONFIG['steps']} | Loss: {loss.item():.4f} | Time: {elapsed:.1f}s")

    # --- D. ä¿å­˜æ¨¡å‹ ---
    torch.save(weights, CONFIG["save_path"])
    print(f"\nğŸ’¾ æ¨¡å‹å‚æ•°å·²ä¿å­˜è‡³: {CONFIG['save_path']}")

    # --- E. ç»ˆææ³›åŒ–æµ‹è¯• ---
    print("\nâš”ï¸ å¼€å§‹å…¨è§’åº¦æ³›åŒ–æµ‹è¯• (Zero-Shot)...")
    angles, accs = [], []
    sorted_angles = sorted(data['test_dict'].keys())
    
    for ang in sorted_angles:
        test_x, test_y = data['test_dict'][ang]
        with torch.no_grad():
            preds = torch.stack([equivariant_circuit(x, weights) for x in q_prep(test_x)])
            # Pred > 0 -> Class 0; Pred < 0 -> Class 1
            correct = ((preds > 0) == (torch.tensor(test_y) == 0)).float().mean()
            acc = correct.item() * 100
            accs.append(acc)
            angles.append(ang)
            
            # çŠ¶æ€æŒ‡ç¤º
            status = "ğŸ”¥ Perfect" if acc > 95 else ("âœ… Good" if acc > 80 else "âš ï¸ Weak")
            print(f"Angle {ang:3d}Â° | Accuracy: {acc:.1f}%  {status}")
    
    # --- F. ç»˜å›¾ ---
    avg_acc = np.mean(accs)
    plt.figure(figsize=(10, 6))
    plt.plot(angles, accs, 'o-', color='#D32F2F', linewidth=2, label=f'Equivariant QML (Avg: {avg_acc:.1f}%)')
    plt.axhline(y=100, color='green', linestyle=':', alpha=0.3)
    plt.axhline(y=90, color='orange', linestyle='--', alpha=0.3, label='Target Threshold')
    plt.ylim(0, 105)
    plt.ylabel('Accuracy (%)')
    plt.xlabel('Rotation Angle (Degrees)')
    plt.title(f"Final Model Performance\nTrained on 0Â°, Tested on All Angles")
    plt.legend(loc='lower right')
    plt.grid(True, alpha=0.3)
    
    save_fig_name = 'best_model_result.png'
    plt.savefig(save_fig_name)
    print(f"\nğŸ“ˆ ç»“æœå›¾è¡¨å·²ä¿å­˜ä¸º '{save_fig_name}'ã€‚å»çœ‹çœ‹å§ï¼")
    plt.show()

if __name__ == "__main__":
    run_best_model()